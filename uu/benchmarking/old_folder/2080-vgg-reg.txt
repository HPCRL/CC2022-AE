========= 512 

&& 0.9282350540161133, 0.09470891952514648, 1.0264320373535156


&& 0.9288344383239746, 0.10312271118164062, 1.03544020652771

==========ours 

&& 0.9665257930755615, 0.1412508487701416, 1.110807180404663


&& 0.987459659576416, 0.23704242706298828, 1.2277567386627197


&& 1.1168787479400635, 0.4683094024658203, 1.5878779888153076


&& 1.5972473621368408, 1.3129801750183105, 2.9129483699798584


&& 3.2679195404052734, 4.563765525817871, 7.834802150726318

========= 1024 

&& 0.9813294410705566, 0.17815065383911133, 1.1720256805419922


&& 0.9641194343566895, 0.21413516998291016, 1.1910886764526367

==========ours 

&& 1.056039571762085, 0.31815242767333984, 1.3870220184326172


&& 1.011888027191162, 0.4108452796936035, 1.4355475902557373


&& 1.2010750770568848, 0.749870777130127, 1.9642348289489746


&& 1.7447073459625244, 1.850351333618164, 3.60813307762146


&& 3.6139042377471924, 5.841970920562744, 9.468942403793335

========= 2048 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 223, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 174, in main
    out_ref = model_ref(input_ref)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 132, in forward
    out = self.block1(x)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/activation.py", line 102, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 1207, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 10.76 GiB total capacity; 9.79 GiB already allocated; 3.44 MiB free; 9.79 GiB reserved in total by PyTorch)

&& 1.071429967880249, 0.5765619277954102, 1.6999311447143555

==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 430, in forward
    out = tconv2d(input, self.weight, self.bias, self.stride,
  File "/home/yufan/labpytorch/uu/layers/conv2d.py", line 135, in forward
    out = padding_calc.recreate_input_tile_f(info, out, next_id)
  File "/home/yufan/labpytorch/uu/utils/padding_calc.py", line 510, in recreate_input_tile_f
    input_tile = pd(input_tile)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/padding.py", line 23, in forward
    return F.pad(input, self.padding, 'constant', self.value)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 4001, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 10.76 GiB total capacity; 9.34 GiB already allocated; 67.44 MiB free; 9.52 GiB reserved in total by PyTorch)

&& 1.1854047775268555, 1.1313934326171875, 2.368870496749878


&& 1.4381461143493652, 1.6170806884765625, 3.107120990753174


&& 2.072530508041382, 3.1994612216949463, 5.324065685272217


&& 4.138169527053833, 8.983336687088013, 13.173808813095093

========= 3072 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 223, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 174, in main
    out_ref = model_ref(input_ref)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-no-cp.py", line 132, in forward
    out = self.block1(x)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/pooling.py", line 162, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/yufan/labpytorch/torch/_jit_internal.py", line 365, in fn
    return if_false(*args, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 659, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 10.76 GiB total capacity; 9.73 GiB already allocated; 71.44 MiB free; 9.73 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-sq-cp.py", line 220, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-ref-sq-cp.py", line 181, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/torch/utils/checkpoint.py", line 98, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/utils/checkpoint.py", line 230, in forward
    input = functions[j](input)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/torch/nn/modules/conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yufan/labpytorch/torch/nn/modules/conv.py", line 395, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 10.76 GiB total capacity; 5.28 GiB already allocated; 43.44 MiB free; 9.51 GiB reserved in total by PyTorch)
==========ours 
Traceback (most recent call last):
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 260, in <module>
    main()
  File "/home/yufan/labpytorch/uu/benchmarking/vgg16-our.py", line 220, in main
    loss.backward()
  File "/home/yufan/labpytorch/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yufan/labpytorch/torch/autograd/__init__.py", line 146, in backward
    Variable._execution_engine.run_backward(
  File "/home/yufan/labpytorch/torch/autograd/function.py", line 89, in apply
    return self._forward_cls.backward(self, *args)  # type: ignore
  File "/home/yufan/labpytorch/uu/utils/checkpoint.py", line 120, in backward
    outputs = ctx.run_function(*detached_inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/sequential.py", line 8, in forward
    inputs = module(*inputs)
  File "/home/yufan/labpytorch/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yufan/labpytorch/uu/layers/relu.py", line 24, in forward
    next_input = F.relu(input, inplace=self.inplace)
  File "/home/yufan/labpytorch/torch/nn/functional.py", line 1207, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 10.76 GiB total capacity; 6.94 GiB already allocated; 523.44 MiB free; 9.07 GiB reserved in total by PyTorch)

&& 1.539597749710083, 2.4169929027557373, 4.07174015045166


&& 1.7076618671417236, 2.9012484550476074, 4.723683595657349


&& 2.388460874557495, 5.121889591217041, 7.625675201416016


&& 4.7191808223724365, 12.389417886734009, 17.2237811088562


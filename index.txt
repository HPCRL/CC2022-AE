[torch/csrc/autograd/engine.cpp] call_function SumBackward0
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function MaxPool2DWithIndicesBackward
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function CudnnConvolutionBackward
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::AccumulateGrad
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function CudnnConvolutionBackward
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::AccumulateGrad
[torch/csrc/autograd/engine.cpp] call_function BackwardHookFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::AccumulateGrad
[torch/csrc/autograd/engine.cpp] call_function SumBackward0
[torch/csrc/autograd/engine.cpp] call_function TiledCopyFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function cMaxPool2dFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::CopyBackwards
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::AccumulateGrad
[torch/csrc/autograd/engine.cpp] call_function TiledConv2dFunctionBackward
[torch/csrc/autograd/engine.cpp] call_function torch::autograd::AccumulateGrad
[torch/csrc/autograd/engine.cpp] call_function TiledConv2dFunctionBackward

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Inside Conv2d forward
input size :  torch.Size([1, 1, 4, 4])
input :  tensor([[[[0.7527, 0.1750, 0.4649, 0.2965],
          [0.4341, 0.3677, 0.0579, 0.8407],
          [0.8873, 0.4013, 0.2498, 0.9730],
          [0.7053, 0.9584, 0.6878, 0.5474]]]], device='cuda:0',
       grad_fn=<BackwardHookFunctionBackward>)
output size :  torch.Size([1, 4, 4])
Inside Conv2d forward
input size :  torch.Size([1, 1, 4, 4])
input :  tensor([[[[ 0.1316,  0.0780,  0.0291, -0.0369],
          [ 0.0984,  0.2688,  0.0115,  0.2102],
          [ 0.1572, -0.0729,  0.4702,  0.4217],
          [ 0.5395,  0.2966,  0.4147,  0.0473]]]], device='cuda:0',
       grad_fn=<BackwardHookFunctionBackward>)
output size :  torch.Size([1, 4, 4])
Inside MaxPool2d forward
input size :  torch.Size([1, 1, 4, 4])
input :  tensor([[[[ 0.0316, -0.0998, -0.0340, -0.0799],
          [-0.0846,  0.1225, -0.1088, -0.1870],
          [-0.1166, -0.2615, -0.1533, -0.0255],
          [ 0.1302, -0.1391,  0.0183,  0.0387]]]], device='cuda:0',
       grad_fn=<BackwardHookFunctionBackward>)
output size :  torch.Size([1, 2, 2])
done ref
Inside MaxPool2d backward
grad_output size :  torch.Size([1, 1, 2, 2])
ref grad_output  :
  tensor([[[[1., 1.],
          [1., 1.]]]], device='cuda:0')
grad_input size :  torch.Size([1, 1, 4, 4])
ref grad_input  : 
 tensor([[[[0., 0., 1., 0.],
          [0., 1., 0., 0.],
          [0., 0., 0., 0.],
          [1., 0., 0., 1.]]]], device='cuda:0')
Inside Conv2d backward
grad_output size :  torch.Size([1, 1, 4, 4])
ref grad_output  :
  tensor([[[[0., 0., 1., 0.],
          [0., 1., 0., 0.],
          [0., 0., 0., 0.],
          [1., 0., 0., 1.]]]], device='cuda:0')
grad_input size :  torch.Size([1, 1, 4, 4])
ref grad_input  : 
 tensor([[[[ 0.0702, -0.0203,  0.0634, -0.1768],
          [-0.0953,  0.0361, -0.4796,  0.1396],
          [-0.1754, -0.5258,  0.2098,  0.0750],
          [ 0.2865, -0.1768, -0.0953,  0.2865]]]], device='cuda:0')
Inside Conv2d backward
grad_output size :  torch.Size([1, 1, 4, 4])
ref grad_output  :
  tensor([[[[ 0.0702, -0.0203,  0.0634, -0.1768],
          [-0.0953,  0.0361, -0.4796,  0.1396],
          [-0.1754, -0.5258,  0.2098,  0.0750],
          [ 0.2865, -0.1768, -0.0953,  0.2865]]]], device='cuda:0')
grad_input size :  torch.Size([1, 1, 4, 4])
ref grad_input  : 
 tensor([[[[ 1.9536e-02,  1.2530e-02,  3.3475e-02, -1.9201e-01],
          [ 2.3501e-04, -9.7156e-03, -3.8378e-01,  2.1789e-02],
          [ 8.1067e-02, -2.4441e-01, -6.4732e-02,  1.6063e-01],
          [-1.0098e-02,  1.5768e-01,  3.8601e-02,  8.5263e-03]]]],
       device='cuda:0')
done ref bkw

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Input 1x1x4x4
L-->R current op 139638781506272
after conv2d 1x1x4x4
L-->R current op 139638781507760
after conv2d 1x1x4x4
L-->R current op 139638781506464
after maxpool2d 1x1x2x2
coord [0, 0]
bwd_out_shape  (2, 2)
fwd_out_shape  (2, 2)
++++++++++++++++++++++++++++++++++++++++++++++++
***input tile torch.Size([1, 1, 4, 4])
in customized Sequential 2
id 139638781506272
== tiled conv2d forward
shape input_tile_for_next
 torch.Size([1, 1, 6, 6])
in customized Sequential 3
id 139638781507760
== tiled conv2d forward
shape input_tile_for_next
 torch.Size([1, 1, 4, 4])
in customized Sequential 3
(2, 2) [2, 2] [0, 1, 0, 1]
coord [0, 1, 0, 1]
out_temp torch.Size([1, 1, 2, 2])

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&


^^^^^cMaxPool2dFunction bwd
input size torch.Size([1, 1, 4, 4])
grad_out size torch.Size([1, 1, 2, 2])
grad_out  tensor([[[[1., 1.],
          [1., 1.]]]], device='cuda:0')
arg size torch.Size([1, 1, 2, 2])
new_grad_out torch.Size([1, 1, 2, 2])
##############grad_in in maxp torch.Size([1, 1, 4, 4])
grad in tensor([[[[0., 0., 1., 0.],
          [0., 1., 0., 0.],
          [0., 0., 0., 0.],
          [1., 0., 0., 1.]]]], device='cuda:0')
@@@ using cudnn bkw
local last ++ input shape torch.Size([1, 1, 6, 6])
local last ++ input tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.1316,  0.0780,  0.0291, -0.0369,  0.0000],
          [ 0.0000,  0.0984,  0.2688,  0.0115,  0.2102,  0.0000],
          [ 0.0000,  0.1572, -0.0729,  0.4702,  0.4217,  0.0000],
          [ 0.0000,  0.5395,  0.2966,  0.4147,  0.0473,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]],
       device='cuda:0', grad_fn=<TiledConv2dFunctionBackward>)
weight shape torch.Size([1, 1, 3, 3])
grad_output shape torch.Size([1, 1, 4, 4])
grad_input torch.Size([1, 1, 6, 6])
padding info :: [1, 1, 1, 1]
new grad_input torch.Size([1, 1, 4, 4])
##############grad_in in conv2d tensor([[[[ 0.0702, -0.0203,  0.0634, -0.1768],
          [-0.0953,  0.0361, -0.4796,  0.1396],
          [-0.1754, -0.5258,  0.2098,  0.0750],
          [ 0.2865, -0.1768, -0.0953,  0.2865]]]], device='cuda:0')
@@@ using cudnn bkw
input grad ++ input shape torch.Size([1, 1, 8, 8])
input grad ++ input tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.7527, 0.1750, 0.4649, 0.2965, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.4341, 0.3677, 0.0579, 0.8407, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.8873, 0.4013, 0.2498, 0.9730, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.7053, 0.9584, 0.6878, 0.5474, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],
       device='cuda:0')
weight shape torch.Size([1, 1, 3, 3])
grad_output shape torch.Size([1, 1, 4, 4])
